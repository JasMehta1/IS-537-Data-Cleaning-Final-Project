{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1cfd36c-5da1-4230-a790-7fa001002c00",
   "metadata": {},
   "source": [
    "# 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16b9318d-6f3b-4b1a-b846-e5d9b112b9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c86dbd-49db-4cc7-a3d4-6b9f4ca971ff",
   "metadata": {},
   "source": [
    "# 1. Extracting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b8f009-3fb1-43bd-a2fd-9dd82a927ac9",
   "metadata": {},
   "source": [
    "### 1. 1. Section Enrollment Data - After 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee808732-09eb-484e-b6f1-b40cf5dc332b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 205132 rows from 17 files\n"
     ]
    }
   ],
   "source": [
    "# Load Scraped data\n",
    "section_final_df = pd.read_csv(\"Extracted_files/courses_processed.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b98dd6-e725-4bf9-b7f0-cb2c04bb8d2f",
   "metadata": {},
   "source": [
    "### 1. 2. Grades Data - After 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9618527-0991-4f19-b2d2-30cf971c1715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14 files with 19284 rows (Spring/Fall, after 2017).\n"
     ]
    }
   ],
   "source": [
    "gpa_base_url = \"https://raw.githubusercontent.com/wadefagen/datasets/main/gpa/raw/\"\n",
    "\n",
    "# Files from Spring and Fall (2017–2024) only\n",
    "gpa_files = []\n",
    "for year in range(2017, 2025):\n",
    "    gpa_files.extend([\n",
    "        f\"sp{year}.csv\",\n",
    "        f\"fa{year}.csv\"\n",
    "    ])\n",
    "\n",
    "# To hold all loaded data\n",
    "final_gpa_df = []\n",
    "\n",
    "for file in gpa_files:\n",
    "    url = gpa_base_url + file\n",
    "    try:\n",
    "        # Try UTF-8 first\n",
    "        try:\n",
    "            gpa_df = pd.read_csv(url, encoding=\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            gpa_df = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "        # Extract term and year\n",
    "        name = file.replace(\".csv\", \"\")\n",
    "        raw_term = name[:2].upper()\n",
    "        term_map = {\"SP\": \"SPRING\", \"FA\": \"FALL\"}\n",
    "        term = term_map.get(raw_term, raw_term)\n",
    "        year = int(name[2:])\n",
    "\n",
    "        # Filter here: only SPRING and FALL after 2017\n",
    "        if year > 2017 and term in [\"SPRING\", \"FALL\"]:\n",
    "            gpa_df[\"Year\"] = year\n",
    "            gpa_df[\"Term\"] = term\n",
    "            final_gpa_df.append(gpa_df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {file}: {e}\")\n",
    "\n",
    "# Combine all filtered data\n",
    "all_gpa_df = pd.concat(final_gpa_df, ignore_index=True)\n",
    "\n",
    "# Drop rows with missing Course values in GPA\n",
    "all_gpa_df = all_gpa_df[all_gpa_df[\"Course\"].notnull()]\n",
    "\n",
    "# Convert Course (GPA) to string and remove decimal\n",
    "all_gpa_df[\"Course\"] = all_gpa_df[\"Course\"].astype(int).astype(str)\n",
    "\n",
    "print(f\"Loaded {len(final_gpa_df)} files with {len(all_gpa_df)} rows (Spring/Fall, after 2017).\")\n",
    "all_gpa_df.to_csv(\"Extracted_files/1_filtered_gpa_sp_fa_after_2017.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171b125-1e5c-45f8-9790-33ce0d073298",
   "metadata": {},
   "source": [
    "### 1. 3. Merge Two Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "be38d7ca-3972-4343-bbf4-a7d035336ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Course' in GPA is str and stripped to match 'Number'\n",
    "all_gpa_df[\"Course\"] = all_gpa_df[\"Course\"].astype(str).str.strip()\n",
    "\n",
    "# Ensure 'Number' in section data is also str and stripped\n",
    "section_final_df[\"Number\"] = section_final_df[\"Number\"].astype(str).str.strip()\n",
    "\n",
    "# Ensure CRN is the same type in both (int or str), safest to cast to str\n",
    "all_gpa_df[\"CRN\"] = all_gpa_df[\"CRN\"].astype(str).str.strip()\n",
    "section_final_df[\"CRN\"] = section_final_df[\"CRN\"].astype(str).str.strip()\n",
    "\n",
    "# Now perform the join on the required columns\n",
    "merged_df = pd.merge(\n",
    "    section_final_df,\n",
    "    all_gpa_df,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Year\", \"Term\", \"CRN\"],\n",
    "    right_on=[\"Year\", \"Term\", \"CRN\"]\n",
    ")\n",
    "\n",
    "before = merged_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f5a9d-1c66-4e65-9032-2e08443c5c18",
   "metadata": {},
   "source": [
    "### 1. 4. Exporting Merged DB for Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "91af4a2b-13b6-4055-8662-fb2797021d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset has 20042 rows.\n"
     ]
    }
   ],
   "source": [
    "# Preview and save\n",
    "print(f\"Merged dataset has {len(merged_df)} rows.\")\n",
    "merged_df.to_csv(\"Extracted_files/2_merged_uiuc_courses_gpa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532190d-134e-455d-be50-76ff5529cf96",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02751a5d-5694-41df-be5f-955c46f7ee6c",
   "metadata": {},
   "source": [
    "### 2. 1. Checking Common Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ea25dc97-6c58-4bc8-9eb4-537be098c1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  True\n",
      "course_name_check:  False\n",
      "course_no_check:  True\n",
      "section:  False\n",
      "section status:  True\n"
     ]
    }
   ],
   "source": [
    "subject_check = merged_df['Subject_x'].equals(merged_df['Subject_y'])\n",
    "print(\"subject: \", subject_check)\n",
    "\n",
    "course_name_check = merged_df['Name'].equals(merged_df['Course Title'])\n",
    "print(\"course_name_check: \", course_name_check)\n",
    "\n",
    "course_no_check = merged_df['Number'].equals(merged_df['Course'])\n",
    "print(\"course_no_check: \", course_no_check)\n",
    "\n",
    "section_check = merged_df['Section_x'].equals(merged_df['Section_y'])\n",
    "print(\"section: \", section_check)\n",
    "\n",
    "section_status_check = merged_df['Section Status'].equals(merged_df['Status Code'])\n",
    "print(\"section status: \", section_status_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820f1af-db8f-4f36-a689-2dfd814014bd",
   "metadata": {},
   "source": [
    "1. **Subjects:** The subject_x and subject_y columns contain identical information. One of them has been dropped to avoid redundancy.\n",
    "\n",
    "2. **Name vs. Course Title:** Although not textually identical, the Name and Course Title columns represent the same information. Minor differences are due to abbreviations or formatting. These have been reconciled as equivalent.\n",
    "\n",
    "3. **Course Numbers:** The course numbers are consistent across datasets and require no transformation.\n",
    "\n",
    "4. **Sections:** While the section_x and section_y columns are not identical, they are complementary—if one is missing, the other typically contains the correct value. A unified section column has been created by taking the non-null value from either column.\n",
    "\n",
    "5. **Section Status:** The SectionStatus_x and SectionStatus_y columns are identical. One has been dropped to remove duplication.\n",
    "\n",
    "6. **Credit Hours:** Both CreditHours and GPA Credit Hours columns are retained. CreditHours refers to the total available credits for a course, whereas GPA Credit Hours reflects the credits applicable to GPA calculations. These serve distinct analytical purposes.\n",
    "\n",
    "7. **Part of Term:** The PartOfTerm column contains inconsistent formats such as numeric (\"1\", \"2\") and alphabetical (\"A\", \"B\") representations. To standardize, alphabetical values have been replaced with their numeric equivalents: \"A\" → \"1\" and \"B\" → \"2\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b32e49-50fb-4a04-9cec-411858193920",
   "metadata": {},
   "source": [
    "### 2. 2. De-duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a9642f0f-c5d2-4e5d-bc29-448a8ea27038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'section' column: take non-blank value from section_x or section_y\n",
    "merged_df[\"Section\"] = merged_df.apply(\n",
    "    lambda row: row[\"Section_x\"] if pd.notna(row[\"Section_x\"]) and str(row[\"Section_x\"]).strip() != \"\" \n",
    "    else (row[\"Section_y\"] if pd.notna(row[\"Section_y\"]) and str(row[\"Section_y\"]).strip() != \"\" \n",
    "          else \"\"),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38848357-c810-45e7-b401-b390c48b4a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in part_of_term after standardization: <IntegerArray>\n",
      "[1, 2]\n",
      "Length: 2, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Normalize Part of Term: A → 1, B → 2, keep digits as-is\n",
    "merged_df['Part of Term'] = merged_df['Part of Term'].astype(str).str.strip().str.upper()\n",
    "merged_df['Part of Term'] = merged_df['Part of Term'].replace({'A': '1', 'B': '2'})\n",
    "merged_df['Part of Term'] = pd.to_numeric(merged_df['Part of Term'], errors='coerce').astype('Int64')\n",
    "print(\"Unique values in part_of_term after standardization:\", merged_df['Part of Term'].dropna().unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ec0aa854-bf98-40e9-be77-bebd747dfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(columns={'Section': 'Subject/Section', 'Subject_y': 'Subject', 'Number': 'Course_Number', 'Instructors': 'Instructors_Abbr', 'Primary Instructor': 'Instructors_FN', 'Type':'Section Type', 'Type Code':'Section Type Code'})\n",
    "merged_df = merged_df.drop(columns = ['Subject_x', 'YearTerm', 'source_file', 'Sched Type', 'Course ', 'Course', 'Name', 'Status Code', 'Section_x', 'Section_y' ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3ae58-3893-4509-aa05-3f99fd25f433",
   "metadata": {},
   "source": [
    "### 2. 3. Reordering Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ef14babd-920d-4055-b81b-81a4d4265d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['Year', 'Term', 'CRN', 'Subject/Section', 'Section Title', 'Course_Number', 'Course Title', 'Description', 'Part of Term', \n",
    "                       'Degree Attributes', 'Credit Hours', 'Section Credit Hours', 'Section Status', 'Section Type', 'Section Type Code',  \n",
    "                       'Enrollment Status', 'Start Time', 'End Time', 'Days of Week', 'Room', 'Building', 'Instructors_Abbr', 'Instructors_FN',\n",
    "                       'Section Info', 'Schedule Information', 'Average Grade',\n",
    "                       'A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D', 'D-', 'F', 'W', \n",
    "                       'A Range', 'B Range', 'C Range', 'D Range']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae311da-9fb6-45e5-84e6-07e8d03c3535",
   "metadata": {},
   "source": [
    "### 2. 4. Dropping High-Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bec8524a-0bc0-4c93-a40b-ea4fd5dedc1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 columns by missing percentage:\n",
      "A Range                 100.000000\n",
      "B Range                 100.000000\n",
      "C Range                 100.000000\n",
      "D Range                 100.000000\n",
      "Section Title            93.319030\n",
      "Schedule Information     83.444766\n",
      "Section Credit Hours     77.083125\n",
      "Degree Attributes        74.832851\n",
      "Room                     38.434288\n",
      "Building                 38.434288\n",
      "Section Info             20.232512\n",
      "End Time                 14.469614\n",
      "Days of Week             14.245085\n",
      "Part of Term              3.268137\n",
      "Instructors_Abbr          0.239497\n",
      "Instructors_FN            0.184612\n",
      "Year                      0.000000\n",
      "Term                      0.000000\n",
      "CRN                       0.000000\n",
      "Subject/Section           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_percent = merged_df.isnull().mean() * 100\n",
    "print(\"\\nTop 20 columns by missing percentage:\")\n",
    "print(missing_percent.sort_values(ascending=False).head(20))\n",
    "merged_df.drop(columns=missing_percent[missing_percent > 90].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a8fb1-c167-45fd-bb3b-2510285d04b9",
   "metadata": {},
   "source": [
    "### 2. 5. Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4946be5e-b381-44b0-a4b4-0dccfda00cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 77 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "initial_rows = merged_df.shape[0]\n",
    "merged_df.drop_duplicates(inplace=True)\n",
    "removed = initial_rows - merged_df.shape[0]\n",
    "print(f\"Removed {removed} duplicate rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e50cc-9744-4429-bcba-bbb12e1f7816",
   "metadata": {},
   "source": [
    "### 2. 6. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15eb28e1-2304-4623-a4ff-a2f80a079955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill text fields with 'Unknown'\n",
    "text_cols = merged_df.select_dtypes(include='object').columns\n",
    "merged_df[text_cols] = merged_df[text_cols].fillna('Unknown')\n",
    "\n",
    "# Fill numeric grades with 0\n",
    "grade_cols = ['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D', 'D-', 'F', 'W', 'Average Grade']\n",
    "for col in grade_cols:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcaa193-4af1-483e-8906-1f09d0a65bd8",
   "metadata": {},
   "source": [
    "### 2. 7. Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "38d887b0-1915-477d-923a-9427781aa463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip all grades to a maximum of 100%\n",
    "for col in grade_cols:\n",
    "    merged_df[col] = merged_df[col].clip(lower=0, upper=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c419b1-ae61-4747-b78d-72737d86d3ad",
   "metadata": {},
   "source": [
    "### 2. 8. Cleaning Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0b75374-a4f7-43c9-95f8-cf14c7b23a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'term', 'crn', 'subject_section', 'course_number',\n",
      "       'course_title', 'description', 'part_of_term', 'degree_attributes',\n",
      "       'credit_hours', 'section_credit_hours', 'section_status',\n",
      "       'section_type', 'section_type_code', 'enrollment_status', 'start_time',\n",
      "       'end_time', 'days_of_week', 'room', 'building', 'instructors_abbr',\n",
      "       'instructors_fn', 'section_info', 'schedule_information',\n",
      "       'average_grade', 'a_plus', 'a', 'a_minus', 'b_plus', 'b', 'b_minus',\n",
      "       'c_plus', 'c', 'c_minus', 'd_plus', 'd', 'd_minus', 'f', 'w'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names: lowercase, underscores, no extra characters\n",
    "merged_df.columns = (\n",
    "    merged_df.columns.str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('+', '_plus')\n",
    "    .str.replace('-', '_minus')\n",
    "    .str.replace('/', '_')\n",
    ")\n",
    "\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11011c06-7b88-411f-a5c7-6f3f448b85db",
   "metadata": {},
   "source": [
    "### 2. 9. Fix and impute credit hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "18ce5d34-052d-4bf6-a7cb-aec75e666200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize and fill missing credit hours\n",
    "merged_df['credit_hours'] = merged_df['credit_hours'].replace(['nan', 'Unknown'], pd.NA)\n",
    "merged_df['credit_hours'] = pd.to_numeric(merged_df['credit_hours'], errors='coerce')\n",
    "\n",
    "# Impute using mode per (subject_section, course_number)\n",
    "credit_mode = (\n",
    "    merged_df.groupby(['subject_section','course_number'])['credit_hours']\n",
    "    .agg(lambda x: x.dropna().mode().iloc[0] if not x.dropna().mode().empty else pd.NA)\n",
    ")\n",
    "merged_df['credit_hours'] = merged_df.apply(\n",
    "    lambda row: credit_mode.get((row['subject_section'], row['course_number']), row['credit_hours']), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90957a79-e64e-4543-a119-73894b0d1f84",
   "metadata": {},
   "source": [
    "### 2. 10. Final sanity checks and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec9e6d7c-bf27-4c69-97a7-550b03b6b5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 77 rows missing key course fields\n",
      "Saved cleaned dataset\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows with missing course_number or year\n",
    "\n",
    "merged = merged_df[merged_df['course_number'].notna() & merged_df['year'].notna()]\n",
    "print(f\"Dropped {before - merged_df.shape[0]} rows missing key course fields\")\n",
    "\n",
    "# Save cleaned dataset\n",
    "merged.to_csv(\"merged_cleaned_final.csv\", index=False)\n",
    "print(\"Saved cleaned dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
